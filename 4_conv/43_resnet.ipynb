{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3cef3963a310e8bc9e86b71e08ebc0c",
     "grade": false,
     "grade_id": "cell-440df6cfa709812f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise 4. Convolutional networks\n",
    "\n",
    "## Part 3. ResNet\n",
    "\n",
    "In the third part you need to train a convolutional neural network with a ResNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b0b185c50941111bc63f11990e412ab",
     "grade": false,
     "grade_id": "cell-e7fb713b137e5e3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Select data directory\n",
    "import os\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    # course_data_dir = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e0d4635b5905e98963ce92fbfb03375",
     "grade": false,
     "grade_id": "cell-d1a0f2d597ac9692",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48d33ffe246f5459117f53cac15b370d",
     "grade": false,
     "grade_id": "cell-fe95dcf02c6b9c5e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f2b11aa8f0d0377563333bd78493751",
     "grade": false,
     "grade_id": "cell-e5b565cc4aae8e7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## FashionMNIST dataset\n",
    "\n",
    "Let us use the FashionMNIST dataset. It consists of 60,000 training images of 10 classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05dae4d3d681cf9666b90ac940628a83",
     "grade": false,
     "grade_id": "cell-8b0fded08998282c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Min-max scaling to [-1, 1]\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(course_data_dir, 'fashion_mnist')\n",
    "print('Data stored in %s' % data_dir)\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9515e202d9b9f214b97032c7fc387cd2",
     "grade": false,
     "grade_id": "cell-7236520c2892e5d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49ddeb203278e46e4aaa122fac6664eb",
     "grade": false,
     "grade_id": "cell-e505c3b987b78603",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## ResNet\n",
    "\n",
    "Let us train a network with an architecure inspired by [ResNet](https://arxiv.org/pdf/1512.03385.pdf).\n",
    "\n",
    "### ResNet block\n",
    "Our ResNet consists of blocks with two convolutional layers and a skip connection.\n",
    "\n",
    "In the most general case, our implementation should have:\n",
    "\n",
    "<img src=\"resnet_block_04.png\" width=220 style=\"float: right;\">\n",
    "\n",
    "* Two convolutional layers with:\n",
    "    * 3x3 kernel\n",
    "    * no bias terms\n",
    "    * padding with one pixel on both sides\n",
    "    * 2d batch normalization after each convolutional layer.\n",
    "\n",
    "* **The first convolutional layer also (optionally) has:**\n",
    "    * different number of input channels and output channels\n",
    "    * change of the resolution with stride.\n",
    "\n",
    "* The skip connection:\n",
    "    * simply copies the input if the resolution and the number of channels do not change.\n",
    "    * If either the resolution or the number of channels change, the skip connection should have one convolutional layer with:\n",
    "        * 1x1 convolution **without bias**\n",
    "        * change of the resolution with stride (optional)\n",
    "        * different number of input channels and output channels (optional)\n",
    "    * If either the resolution or the number of channels change, the 1x1 convolutional layer is followed by 2d batch normalization.\n",
    "\n",
    "* The ReLU nonlinearity is applied after the first convolutional layer and at the end of the block.\n",
    "\n",
    "**Note: Batch normalization is expected to be right after a convolutional layer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc44ddc69f370f1b5f1d68c0dfb0732f",
     "grade": false,
     "grade_id": "cell-0db2cc6de47fa70d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"resnet_blocks_123.png\" width=650 style=\"float: top;\">\n",
    "\n",
    "The implementation should also handle specific cases such as:\n",
    "\n",
    "Left: The number of channels and the resolution do not change.\n",
    "There are no computations in the skip connection.\n",
    "\n",
    "Middle: The number of channels changes, the resolution does not change.\n",
    "\n",
    "Right: The number of channels does not change, the resolution changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c970ca322994ba8941f555de4baf9b5",
     "grade": false,
     "grade_id": "cell-7c95703d5b7fa14c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Your task is to implement this block. You should use the implementations of layers in `nn.Conv2d`, `nn.BatchNorm2d` as the tests rely on those implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d38adfbfa37edfb193033cf63136c4e",
     "grade": false,
     "grade_id": "cell-5694742fd919140f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          in_channels (int):  Number of input channels.\n",
    "          out_channels (int): Number of output channels.\n",
    "          stride (int):       Controls the stride.\n",
    "        \"\"\"\n",
    "        super(Block, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0e38a695cc58c087fb944435b432e76",
     "grade": true,
     "grade_id": "block",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test your implementation of the Block\n",
    "\n",
    "# The number of channels and resolution do not change\n",
    "batch_size = 20\n",
    "x = torch.zeros(batch_size, 16, 28, 28)\n",
    "block = Block(in_channels=16, out_channels=16)\n",
    "y = block(x)\n",
    "assert y.shape == torch.Size([batch_size, 16, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "# Increase the number of channels\n",
    "block = Block(in_channels=16, out_channels=32)\n",
    "y = block(x)\n",
    "assert y.shape == torch.Size([batch_size, 32, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "# Decrease the resolution\n",
    "block = Block(in_channels=16, out_channels=16, stride=2)\n",
    "y = block(x)\n",
    "assert y.shape == torch.Size([batch_size, 16, 14, 14]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "# Increase the number of channels and decrease the resolution\n",
    "block = Block(in_channels=16, out_channels=32, stride=2)\n",
    "y = block(x)\n",
    "assert y.shape == torch.Size([batch_size, 32, 14, 14]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "print('The shapes seem to be ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53ed1ca9da16198ce7eb9a79db3efce7",
     "grade": true,
     "grade_id": "block_relus",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a cell used for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51b00d6afb30e112db879c4c22150b81",
     "grade": true,
     "grade_id": "block_batch_norm",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a cell used for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c1c1c641143426800b594ba413f0bb0",
     "grade": false,
     "grade_id": "cell-0162fb4406cb8e15",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Group of blocks\n",
    "\n",
    "ResNet consists of several groups of blocks. The first block in a group may change the number of channels (often multiples the number by 2) and subsample (using strides).\n",
    "\n",
    "<img src=\"resnet_group.png\" width=500 style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e619dcb4f94df39e95c1c84b81cd3165",
     "grade": false,
     "grade_id": "cell-b1930fef0ab076c3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us implement a group of blocks in this cell\n",
    "class GroupOfBlocks(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_blocks, stride=1):\n",
    "        super(GroupOfBlocks, self).__init__()\n",
    "\n",
    "        first_block = Block(in_channels, out_channels, stride)\n",
    "        other_blocks = [Block(out_channels, out_channels) for _ in range(1, n_blocks)]\n",
    "        self.group = nn.Sequential(first_block, *other_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.group(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ae5fb47e1118b4873e93d55ed8b1c9e",
     "grade": false,
     "grade_id": "cell-7481f327aee03c38",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's test it\n",
    "group = GroupOfBlocks(in_channels=10, out_channels=20, n_blocks=3)\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "506af15e210ba69d4fed34ed84c83234",
     "grade": false,
     "grade_id": "cell-71e97cde35d51918",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### ResNet\n",
    "\n",
    "Let us mplement a ResNet with the following architecture. It contains three groups of blocks, each group having two basic blocks.\n",
    "\n",
    "<img src=\"resnet.png\" width=900 style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf6f75ad5ead6e051481f9ceba24e5bb",
     "grade": false,
     "grade_id": "cell-f0c465ad6f77bfc9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The cell below contains the implementation of all the layers except for the groups of blocks. Your task is to insert the groups of blocks in the middle.\n",
    "\n",
    "Note:\n",
    "* The number of channels in the second **group** should be double the number of channels in the first **group**, the number of channels in the third **group** should be four times the number of channels in the first **group**.\n",
    "* The second and the third **group** should reduce the resolution by `stride=2`, as shown in the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4887634d368b55faf02954f91902e2fd",
     "grade": false,
     "grade_id": "cell-b44918fa89e59c40",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_blocks, n_channels=64, num_classes=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_blocks (list):   A list with three elements which contains the number of blocks in \n",
    "                             each of the three groups of blocks in ResNet.\n",
    "                             For instance, n_blocks = [2, 4, 6] means that the first group has two blocks,\n",
    "                             the second group has four blocks and the third one has six blocks.\n",
    "          n_channels (int):  Number of channels in the first group of blocks.\n",
    "          num_classes (int): Number of classes.\n",
    "        \"\"\"\n",
    "        assert len(n_blocks) == 3, \"The number of groups should be three.\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_channels, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4, stride=1)\n",
    "        self.fc = nn.Linear(4*n_channels, num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        if verbose: print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        if verbose: print('conv1:  ', x.shape)\n",
    "        x = self.bn1(x)\n",
    "        if verbose: print('bn1:    ', x.shape)\n",
    "        x = self.relu(x)\n",
    "        if verbose: print('relu:   ', x.shape)\n",
    "        x = self.maxpool(x)\n",
    "        if verbose: print('maxpool:', x.shape)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        if verbose: print('avgpool:', x.shape)\n",
    "\n",
    "        x = x.view(-1, self.fc.in_features)\n",
    "        if verbose: print('x.view: ', x.shape)\n",
    "        x = self.fc(x)\n",
    "        if verbose: print('out:    ', x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bceef5e14b8945c01ec62757eb7f043",
     "grade": false,
     "grade_id": "cell-bae324fd2f70f08e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a network with 2 block in each of the three groups\n",
    "n_blocks = [2, 2, 2]  # number of blocks in the three groups\n",
    "net = ResNet(n_blocks, n_channels=10)\n",
    "net.to(device)\n",
    "\n",
    "# Feed a batch of images from the training data to test the network\n",
    "with torch.no_grad():\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.to(device)\n",
    "    print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "    y = net.forward(images, verbose=True)\n",
    "    print(y.shape)\n",
    "    assert y.shape == torch.Size([32, 10]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "print('The shapes to be ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d0761bf8b0e60b55728ba5981db176f",
     "grade": false,
     "grade_id": "cell-15b052b156ee3862",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us print the architecture of the network\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71ad23804ee4f20b1aa0ff5499a14dae",
     "grade": false,
     "grade_id": "cell-9de9a4ddf89efc42",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us now train the ResNet using the same training loop\n",
    "n_blocks = [2, 2, 2]  # number of blocks in the three groups\n",
    "net = ResNet(n_blocks, n_channels=16)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58659a9b7f0f1499637f04664e6db398",
     "grade": false,
     "grade_id": "cell-50efe3e46b071ec9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = 200  # mini-batches\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        # Transfer to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i % print_every) == (print_every-1):\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if skip_training:\n",
    "            break\n",
    "    if skip_training:\n",
    "        break\n",
    "\n",
    "    # Print accuracy after every epoch\n",
    "    accuracy = compute_accuracy(net, testloader)\n",
    "    print('Accuracy of the network on the test images: %.3f' % accuracy)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08941fbd2953e25da378c4226c5a6488",
     "grade": false,
     "grade_id": "cell-6b2ab46dba3aa322",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You should get the test accuracy at about 90-91%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69ea9b19ef5263efed4c58b3db96cf23",
     "grade": true,
     "grade_id": "cell-cd608a7294f2ceb6",
     "locked": true,
     "points": 0.001,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Save the network to a file, submit this file together with your notebook\n",
    "filename = '4_resnet.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
    "        if do_save == 'yes':\n",
    "            torch.save(net.state_dict(), filename)\n",
    "            print('Model saved to %s' % filename)\n",
    "        else:\n",
    "            print('Model not saved')\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
    "else:\n",
    "    net = ResNet(n_blocks, n_channels=16)\n",
    "    net.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "    net.to(device)\n",
    "    print('Model loaded from %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f420b734e91bcc49286c70c043995b25",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print('Accuracy of the network on the test images: %.3f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
